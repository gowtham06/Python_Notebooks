{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "corpus = pd.read_pickle('SST2.pkl')\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Activation, Dense, Dropout, SpatialDropout1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "word_freqs = collections.Counter()\n",
    "word_polarity=dict()\n",
    "num_recs = len(sentences)\n",
    "label_list=[]\n",
    "for index,sentence in enumerate(sentences):\n",
    "    label_list.append(labels[index])\n",
    "    words=nltk.word_tokenize(sentence.lower())\n",
    "    pos_tags=nltk.pos_tag(words)\n",
    "    word2tag={ item[0]:item[1] for item in pos_tags}\n",
    "#     print(word2tag)\n",
    "    if(len(words)>max_len):\n",
    "        max_len=len(words)\n",
    "    for word in words:\n",
    "        if word2tag[word] in ['JJ','JJS','JJS','RB','RBR','RBS']:\n",
    "#             print(word)\n",
    "            word_freqs[word]+=1\n",
    "            word_polarity[word]=TextBlob(word).sentiment.polarity\n",
    "nos_classes=len(list(set(labels)))\n",
    "label_set_list=list(set(labels))\n",
    "MAX_FEATURES=7000\n",
    "MAX_SENTENCE_LENGTH=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = min(MAX_FEATURES, len(word_freqs)) + 2\n",
    "word2polarity = {x[0]: word_polarity[x[0]] for i, x in\n",
    "enumerate(word_freqs.most_common(MAX_FEATURES))}\n",
    "word2polarity[\"PAD\"]=0\n",
    "word2polarity[\"UNK\"]=0\n",
    "# index2word = {v:k for k, v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'new'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-e8e04b07b2a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mword2tag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'JJ'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'JJS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'JJS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'RB'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'RBR'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'RBS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword2polarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mseqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2polarity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'new'"
     ]
    }
   ],
   "source": [
    "X = np.empty((num_recs, ), dtype=list)\n",
    "nos_classes=2\n",
    "y = np.zeros((num_recs, nos_classes))\n",
    "i = 0\n",
    "# f_train = open(os.path.join(current_dir, file_name), 'rb')\n",
    "for index,sentence in enumerate(sentences):\n",
    "    l=[0]*nos_classes\n",
    "    seqs=[]\n",
    "    words=nltk.word_tokenize(sentence.lower())\n",
    "    for word in words:\n",
    "        if word2tag[word] in ['JJ','JJS','JJS','RB','RBR','RBS']:\n",
    "            if word in word2polarity.keys():\n",
    "                seqs.append(word2polarity[word])\n",
    "            else:\n",
    "                seqs.append(word2polarity['UNK'])\n",
    "    X[i]=seqs\n",
    "    l[label_set_list.index(labels[index])]=1\n",
    "    y[i]=l\n",
    "    i+=1\n",
    "MAX_SENTENCE_LENGTH=80\n",
    "X=sequence.pad_sequences(X,maxlen=MAX_SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63723, 80)\n"
     ]
    }
   ],
   "source": [
    "Xtrain,Xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2)\n",
    "print(Xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gowthamkannan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(80, input_dim=80, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 80)                6480      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 80, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 80, 100)           1100      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 16, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16, 100)           100100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 3, 100)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 3, 32)             32032     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               3300      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 143,214\n",
      "Trainable params: 143,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Reshape\n",
    "model = Sequential()\n",
    "# model.add(Embedding(vocab_size, MAX_SENTENCE_LENGTH, input_length=MAX_SENTENCE_LENGTH))\n",
    "model.add(Dense(MAX_SENTENCE_LENGTH, input_dim=MAX_SENTENCE_LENGTH, init='glorot_uniform', activation='relu')) \n",
    "model.add(Reshape((MAX_SENTENCE_LENGTH, 1)))\n",
    "model.add(Conv1D(filters=100, kernel_size=10, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5))\n",
    "model.add(Conv1D(filters=100, kernel_size=10, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5))\n",
    "model.add(Conv1D(filters=32, kernel_size=10, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63723 samples, validate on 15931 samples\n",
      "Epoch 1/5\n",
      "63723/63723 [==============================] - 66s 1ms/step - loss: 0.6800 - acc: 0.5501 - val_loss: 0.6766 - val_acc: 0.5591\n",
      "Epoch 2/5\n",
      "63723/63723 [==============================] - 64s 1ms/step - loss: 0.6745 - acc: 0.5591 - val_loss: 0.6752 - val_acc: 0.5590\n",
      "Epoch 3/5\n",
      "63723/63723 [==============================] - 63s 990us/step - loss: 0.6740 - acc: 0.5590 - val_loss: 0.6753 - val_acc: 0.5592\n",
      "Epoch 4/5\n",
      "63723/63723 [==============================] - 65s 1ms/step - loss: 0.6739 - acc: 0.5594 - val_loss: 0.6752 - val_acc: 0.5593\n",
      "Epoch 5/5\n",
      "63675/63723 [============================>.] - ETA: 0s - loss: 0.6735 - acc: 0.5594"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=75\n",
    "NUM_EPOCHS=5\n",
    "history=model.fit(Xtrain,ytrain,batch_size=BATCH_SIZE,epochs=NUM_EPOCHS,validation_data=(Xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(history.history[\"acc\"], color=\"g\", label=\"Train\")\n",
    "plt.plot(history.history[\"val_acc\"], color=\"b\", label=\"Validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(history.history[\"loss\"], color=\"g\", label=\"Train\")\n",
    "plt.plot(history.history[\"val_loss\"], color=\"b\", label=\"Validation\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
